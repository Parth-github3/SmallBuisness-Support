{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Home page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import streamlit as st\n",
    "import base64  # For embedding the WhatsApp logo\n",
    "\n",
    "# Introduction Text\n",
    "st.markdown(\"\"\"\n",
    "### Hello mate!\\n\n",
    "This app will make your buisness go with a boom!\\n\n",
    "        This app is a customizable AI-powered customer support chatbot. Features include:\\n\n",
    "            - Multilingual support\n",
    "            - Booking management\n",
    "            - Product information retrieval\n",
    "            - Contextual query handling\n",
    "            - Customizable responses for businesses\n",
    "            - Financial Adivisor with Dept Analysis\n",
    "\"\"\")\n",
    "    \n",
    "\n",
    "# Description\n",
    "st.markdown(\"**Description about app's functions**\")\n",
    "\n",
    "with st.expander(\"About Query...\"):\n",
    "    st.markdown(\"\"\"\n",
    "    In **Query**, you can resolve any general queries or questions related to the buisness you have.\\n\n",
    "    \"\"\")\n",
    "\n",
    "with st.expander(\"About Booking...\"):\n",
    "    st.markdown(\"\"\"\n",
    "In **Booking** page, you can book, cancel or reschedule any product or service you want directly.\\n                          \n",
    "\"\"\")\n",
    "    \n",
    "with st.expander(\"About Product Information...\"):\n",
    "    st.markdown(\"\"\"\n",
    "In **Product Information** page, you can get product information you want to search for.\\n                                               \n",
    "\"\"\")\n",
    "\n",
    "with st.expander(\"About Customized Responses...\"):\n",
    "    st.markdown(\"\"\"\n",
    "In **Customized Responses** page, you can get all the detailed description of a product or service.\\n                          \n",
    "\"\"\")\n",
    "    \n",
    "with st.expander(\"About Chat Bot...\"):\n",
    "    st.markdown(\"\"\"\n",
    "In **Chat Bot** page, you can chat with our chatbot and access all the features mentioned above with chatting.\\n\n",
    "Like you can ask for a haircut, choose the right haircut offered by the salon, and book an appointment with it.\\n                                               \n",
    "\"\"\") \n",
    "\n",
    "with st.expander(\"About Financial Advisor...\"):\n",
    "    st.markdown(\"\"\"\n",
    "In **Financial Advisor** page, generates customized financial recommendations and visualizes financial distribution using graphs.\\n\n",
    " The inputs include revenue, expenses, savings goals, and investment plans.\\n                          \n",
    "\"\"\")  \n",
    "\n",
    "# Define the WhatsApp number (including country code) and the default message\n",
    "WHATSAPP_NUMBER = \"+916354252779\"  # Replace with the actual WhatsApp number\n",
    "DEFAULT_MESSAGE = \"Hello! I would like to inquire about your services.\"  # Replace with your desired message\n",
    "\n",
    "# URL to open WhatsApp chat\n",
    "WHATSAPP_URL = f\"https://wa.me/{WHATSAPP_NUMBER}?text={DEFAULT_MESSAGE}\"\n",
    "\n",
    "################################### Streamlit Page #######################################\n",
    "st.title(\"Contact Us\")\n",
    "\n",
    "# Try using the full file path to avoid issues\n",
    "logo_path = \"whatsapp_logo.png\"  # Path to the logo file (use full path if needed)\n",
    "\n",
    "try:\n",
    "    st.markdown(\n",
    "        f\"\"\"\n",
    "        <a href=\"{WHATSAPP_URL}\" target=\"_blank\">\n",
    "            <img src=\"{logo_path}\" alt=\"WhatsApp Logo\" width=\"100\">\n",
    "        </a>\n",
    "        \"\"\",\n",
    "        unsafe_allow_html=True\n",
    "    )\n",
    "except Exception as e:\n",
    "    st.error(\"WhatsApp logo could not be loaded. Please ensure the image file exists.\")\n",
    "    st.write(f\"Error: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Query page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Requirements\n",
    "from langchain_groq import ChatGroq\n",
    "import streamlit as st\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from googletrans import Translator  # Multilingual support\n",
    "\n",
    "\n",
    "#LLM Model\n",
    "llama = ChatGroq(\n",
    "    model=\"LLaMA3-70B-8192\",\n",
    "    groq_api_key='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',\n",
    "    temperature=0.0\n",
    ")\n",
    "\n",
    "translator = Translator()  # Translator for multilingual support\n",
    "\n",
    "##################################### Base Chains ###########################################\n",
    "# 1. Input Translation Chain\n",
    "def translate_input(user_input):\n",
    "    \"\"\"Auto-detect and translate the user input to English.\"\"\"\n",
    "    try:\n",
    "        detected_lang = translator.detect_language(user_input).result\n",
    "        if detected_lang != \"English\":\n",
    "            user_input = translator.translate(user_input, destination_language=\"English\").result\n",
    "        return user_input, detected_lang\n",
    "    except Exception as e:\n",
    "        #st.error(f\"Error in language detection or translation: {e}\")\n",
    "        return user_input, \"English\"  # Default to English if detection fails\n",
    "\n",
    "# 2. Output Translation Chain\n",
    "def translate_output(response, target_lang):\n",
    "    \"\"\"Translate response back to the user's language.\"\"\"\n",
    "    try:\n",
    "        if target_lang != \"English\":\n",
    "            response = translator.translate(response, destination_language=target_lang).result\n",
    "        return response\n",
    "    except Exception as e:\n",
    "        #st.error(f\"Error in translating response: {e}\")\n",
    "        return response  # Return the original response if translation fails\n",
    "\n",
    "# 3. Fallback Error Handling Chain\n",
    "fallback_chain = (\n",
    "    ChatPromptTemplate.from_template(\"\"\"\n",
    "You are a fallback assistant. If the system cannot handle the query, respond politely and suggest contacting support.\n",
    "Input Query: \"{query}\"\n",
    "\"\"\")\n",
    "    | llama\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "##################################### Advanced Chains ###########################################\n",
    "# 4. General Query Chain\n",
    "query_chain = (\n",
    "    ChatPromptTemplate.from_template(\"\"\"\n",
    "You are a customer support assistant. The user has the query: \"{query}\". \n",
    "Respond with a clear and concise answer. If you don't know the answer, ask for more details or suggest contacting support.\n",
    "\"\"\")\n",
    "    | llama\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "# 8. Contextual Query Chain\n",
    "context_chain = (\n",
    "    ChatPromptTemplate.from_template(\"\"\"\n",
    "You are a follow-up assistant. Based on the previous interaction: \"{previous_interaction}\", suggest a related query or provide further assistance.\n",
    "\"\"\")\n",
    "    | llama\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "user_input = st.text_input(\"Ask your question here:\")\n",
    "\n",
    "if user_input:\n",
    "    # Base Chain: Translate input to English\n",
    "    translated_input, user_lang = translate_input(user_input)\n",
    "    response = query_chain.invoke({\"query\": translated_input})\n",
    "    # Base Chain: Translate output back to user language\n",
    "    if response:\n",
    "        translated_response = translate_output(response, user_lang)\n",
    "        st.write(\"Response:\", translated_response)\n",
    "\n",
    "    # Contextual Suggestions\n",
    "    if st.checkbox(\"Need more help? Get suggestions.\"):\n",
    "        contextual_response = context_chain.invoke({\"previous_interaction\": translated_input})\n",
    "        st.write(\"Suggestions:\", contextual_response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Product information page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Requirements\n",
    "from langchain_groq import ChatGroq\n",
    "import streamlit as st\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from googletrans import Translator  # Multilingual support\n",
    "import matplotlib.pyplot as plt  # For visualization\n",
    "import random  # For generating dummy demand data\n",
    "\n",
    "# LLM Model\n",
    "llama = ChatGroq(\n",
    "    model=\"LLaMA3-70B-8192\",\n",
    "    groq_api_key='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',\n",
    "    temperature=0.0\n",
    ")\n",
    "\n",
    "translator = Translator()  # Translator for multilingual support\n",
    "\n",
    "##################################### Base Chains ###########################################\n",
    "# 1. Input Translation Chain\n",
    "def translate_input(user_input):\n",
    "    \"\"\"Auto-detect and translate the user input to English.\"\"\"\n",
    "    try:\n",
    "        detected_lang = translator.detect_language(user_input).result\n",
    "        if detected_lang != \"English\":\n",
    "            user_input = translator.translate(user_input, destination_language=\"English\").result\n",
    "        return user_input, detected_lang\n",
    "    except Exception as e:\n",
    "        return user_input, \"English\"  # Default to English if detection fails\n",
    "\n",
    "# 2. Output Translation Chain\n",
    "def translate_output(response, target_lang):\n",
    "    \"\"\"Translate response back to the user's language.\"\"\"\n",
    "    try:\n",
    "        if target_lang != \"English\":\n",
    "            response = translator.translate(response, destination_language=target_lang).result\n",
    "        return response\n",
    "    except Exception as e:\n",
    "        return response  # Return the original response if translation fails\n",
    "\n",
    "# 3. Fallback Error Handling Chain\n",
    "fallback_chain = (\n",
    "    ChatPromptTemplate.from_template(\"\"\"\n",
    "You are a fallback assistant. If the system cannot handle the query, respond politely and suggest contacting support.\n",
    "Input Query: \"{query}\"\n",
    "\"\"\")\n",
    "    | llama\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "##################################### Advanced Chains ###########################################\n",
    "# 4. General Query Chain\n",
    "# 6. Product Information Chain\n",
    "product_info_chain = (\n",
    "    ChatPromptTemplate.from_template(\"\"\"\n",
    "You are a knowledgeable sales assistant. The user is asking about: \"{product}\". \n",
    "Provide detailed information including features, pricing, and availability.\n",
    "\"\"\")\n",
    "    | llama\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "# 8. Contextual Query Chain\n",
    "context_chain = (\n",
    "    ChatPromptTemplate.from_template(\"\"\"\n",
    "You are a follow-up assistant. Based on the previous interaction: \"{previous_interaction}\", suggest a related query or provide further assistance.\n",
    "\"\"\")\n",
    "    | llama\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "##################################### Upselling Chain ###########################################\n",
    "# 9. Upselling Chain\n",
    "upselling_chain = (\n",
    "    ChatPromptTemplate.from_template(\"\"\"\n",
    "You are an AI sales assistant. The user is interested in \"{product}\". \n",
    "Suggest related or higher-tier products/services and their potential benefits.\n",
    "\"\"\")\n",
    "    | llama\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "##################################### Streamlit Application ###########################################\n",
    "product = st.text_input(\"Product Name:\")\n",
    "if product:\n",
    "    # Base Chain: Translate input to English\n",
    "    translated_input, user_lang = translate_input(product)\n",
    "\n",
    "    # Product Info Chain\n",
    "    if product:\n",
    "        response = product_info_chain.invoke({\"product\": product})\n",
    "    else:\n",
    "        response = fallback_chain.invoke({\"query\": \"Missing product details.\"})\n",
    "    \n",
    "    # Base Chain: Translate output back to user language\n",
    "    if response:\n",
    "        translated_response = translate_output(response, user_lang)\n",
    "        st.write(\"Response:\", translated_response)\n",
    "\n",
    "    # Contextual Suggestions\n",
    "    if st.checkbox(\"Need more help? Get suggestions.\"):\n",
    "        contextual_response = context_chain.invoke({\"previous_interaction\": translated_input})\n",
    "        st.write(\"Suggestions:\", contextual_response)\n",
    "\n",
    "    # Upselling Recommendations\n",
    "    st.subheader(\"Upselling Recommendations\")\n",
    "    upselling_response = upselling_chain.invoke({\"product\": product})\n",
    "    st.write(\"Upselling Suggestions:\", upselling_response)\n",
    "\n",
    "    # Visualize Upselling Suggestions\n",
    "    upsell_products = [f\"{product} Pro\", f\"{product} Premium\", f\"{product} Bundle\"]\n",
    "    upsell_demand = [random.randint(20, 100) for _ in upsell_products]\n",
    "\n",
    "    st.write(\"**Demand for Upselling Options:**\")\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.bar(upsell_products, upsell_demand, color=\"lightblue\")\n",
    "    ax.set_title(\"Upselling Demand Visualization\")\n",
    "    ax.set_xlabel(\"Products\")\n",
    "    ax.set_ylabel(\"Demand Score\")\n",
    "    st.pyplot(fig)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Financial support page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_groq import ChatGroq\n",
    "import streamlit as st\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from googletrans import Translator  # Multilingual support\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# LLM Model\n",
    "llama = ChatGroq(\n",
    "    model=\"LLaMA3-70B-8192\",\n",
    "    groq_api_key='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',\n",
    "    temperature=0.0\n",
    ")\n",
    "\n",
    "translator = Translator()  # Translator for multilingual support\n",
    "\n",
    "##################################### Base Chains ###########################################\n",
    "# 1. Input Translation Chain\n",
    "def translate_input(user_input):\n",
    "    \"\"\"Auto-detect and translate the user input to English.\"\"\"\n",
    "    try:\n",
    "        detected_lang = translator.detect_language(user_input).result\n",
    "        if detected_lang != \"English\":\n",
    "            user_input = translator.translate(user_input, destination_language=\"English\").result\n",
    "        return user_input, detected_lang\n",
    "    except Exception as e:\n",
    "        return user_input, \"English\"  # Default to English if detection fails\n",
    "\n",
    "# 2. Output Translation Chain\n",
    "def translate_output(response, target_lang):\n",
    "    \"\"\"Translate response back to the user's language.\"\"\"\n",
    "    try:\n",
    "        if target_lang != \"English\":\n",
    "            response = translator.translate(response, destination_language=target_lang).result\n",
    "        return response\n",
    "    except Exception as e:\n",
    "        return response  # Return the original response if translation fails\n",
    "\n",
    "# 3. Fallback Error Handling Chain\n",
    "fallback_chain = (\n",
    "    ChatPromptTemplate.from_template(\"\"\"\n",
    "You are a fallback assistant. If the system cannot handle the query, respond politely and suggest contacting support.\n",
    "Input Query: \"{query}\"\n",
    "\"\"\")\n",
    "    | llama\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "##################################### Financial Advisor Chains ###########################################\n",
    "# Custom Financial Advice Chain\n",
    "financial_chain = (\n",
    "    ChatPromptTemplate.from_template(\"\"\"\n",
    "You are a financial advisor for small businesses. The business owner provided the following details:\n",
    "Revenue: {revenue}\n",
    "Expenses: {expenses}\n",
    "Savings Goal: {savings_goal}\n",
    "Investment Plan: {investment_plan}\n",
    "Debt: {debt}\n",
    "\n",
    "Provide detailed financial recommendations with the following:\n",
    "1. Ways to optimize expenses.\n",
    "2. Strategies to achieve the savings goal.\n",
    "3. Insights on the investment plan, including feasibility and potential risks.\n",
    "4. Debt reduction strategies tailored to the user's financial condition.\n",
    "5. Suggestions for reinvestment into the business.\n",
    "\n",
    "Respond in a professional tone with actionable insights.\n",
    "\"\"\")\n",
    "    | llama\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "##################################### Streamlit Financial Advisor Page ###########################################\n",
    "\n",
    "# Form for user input\n",
    "with st.form(\"financial_advisor_form\"):\n",
    "    st.header(\"Enter Business Financial Details:\")\n",
    "    \n",
    "    # Financial inputs\n",
    "    revenue = st.number_input(\"Monthly Revenue ($)\", min_value=0, step=1)\n",
    "    expenses = st.number_input(\"Monthly Expenses ($)\", min_value=0, step=1)\n",
    "    savings_goal = st.number_input(\"Savings Goal ($)\", min_value=0, step=1)\n",
    "    \n",
    "    # Debt information\n",
    "    debt = st.number_input(\"Outstanding Debt ($)\", min_value=0, step=1)\n",
    "    debt_interest = st.number_input(\n",
    "        \"Debt Interest Rate (%)\", min_value=0.0, step=0.1,\n",
    "        help=\"Enter the annual interest rate on your outstanding debt.\"\n",
    "    )\n",
    "    monthly_payment = st.number_input(\n",
    "        \"Monthly Debt Payment ($)\", min_value=0, step=100,\n",
    "        help=\"Enter the amount you pay monthly to service the debt.\"\n",
    "    )\n",
    "    \n",
    "    # Investment plan section (before the button)\n",
    "    st.subheader(\"Describe Your Investment Plan:\")\n",
    "    investment_plan = st.text_area(\n",
    "        \"Investment Plan (e.g., expand operations, invest in marketing, etc.)\",\n",
    "        placeholder=\"Briefly describe your investment plan\"\n",
    "    )\n",
    "\n",
    "    # Submit button\n",
    "    submit_financials = st.form_submit_button(\"Get Financial Advice\")\n",
    "\n",
    "    if submit_financials:\n",
    "        if investment_plan and revenue > 0 and expenses > 0:\n",
    "            # Generate Financial Advice\n",
    "            response = financial_chain.invoke({\n",
    "                \"revenue\": revenue,\n",
    "                \"expenses\": expenses,\n",
    "                \"savings_goal\": savings_goal,\n",
    "                \"investment_plan\": investment_plan,\n",
    "                \"debt\": f\"{debt} at {debt_interest}% interest with ${monthly_payment}/month payment\"\n",
    "            })\n",
    "\n",
    "            # Display Financial Advice\n",
    "            st.subheader(\"Customized Financial Recommendations:\")\n",
    "            st.write(response)\n",
    "\n",
    "            # Financial Distribution Visualization\n",
    "            st.subheader(\"Financial Distribution:\")\n",
    "            financial_data = {\n",
    "                \"Revenue\": revenue,\n",
    "                \"Expenses\": expenses,\n",
    "                \"Savings Goal\": savings_goal,\n",
    "                \"Debt Payment\": monthly_payment * 12,\n",
    "                \"Remaining Funds\": max(revenue - expenses - savings_goal - (monthly_payment * 12), 0)\n",
    "            }\n",
    "\n",
    "            fig, ax = plt.subplots(figsize=(6, 6))\n",
    "            labels = financial_data.keys()\n",
    "            sizes = financial_data.values()\n",
    "            explode = (0.1, 0, 0, 0, 0)  # Emphasize 'Revenue'\n",
    "            colors = ['#2E91E5', '#E15F99', '#1CA71C', '#FB0D0D', '#FFC300']\n",
    "\n",
    "            ax.pie(sizes, explode=explode, labels=labels, autopct='%1.1f%%', startangle=140, colors=colors)\n",
    "            ax.axis('equal')  # Equal aspect ratio ensures the pie is drawn as a circle.\n",
    "\n",
    "            st.pyplot(fig)\n",
    "\n",
    "            # Debt Analysis\n",
    "            st.subheader(\"Debt Analysis:\")\n",
    "            total_debt_payment = monthly_payment * 12\n",
    "            remaining_debt = debt - total_debt_payment if debt > total_debt_payment else 0\n",
    "            interest_paid = debt * (debt_interest / 100)\n",
    "\n",
    "            st.write(f\"Total Debt Paid This Year: **${total_debt_payment:,.2f}**\")\n",
    "            st.write(f\"Remaining Debt After a Year: **${remaining_debt:,.2f}**\")\n",
    "            st.write(f\"Estimated Interest Paid This Year: **${interest_paid:,.2f}**\")\n",
    "\n",
    "            if remaining_debt > 0:\n",
    "                st.write(\n",
    "                    \"Consider increasing your monthly debt payments or restructuring the debt to reduce interest payments.\"\n",
    "                )\n",
    "            else:\n",
    "                st.write(\"Congratulations! You are on track to clear your debt.\")\n",
    "        else:\n",
    "            st.warning(\"Please enter a valid investment plan to proceed.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Customisation page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Requirements\n",
    "from langchain_groq import ChatGroq\n",
    "import streamlit as st\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from googletrans import Translator  # Multilingual support\n",
    "\n",
    "# LLM Model\n",
    "llama = ChatGroq(\n",
    "    model=\"LLaMA3-70B-8192\",\n",
    "    groq_api_key='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',\n",
    "    temperature=0.0\n",
    ")\n",
    "\n",
    "translator = Translator()  # Translator for multilingual support\n",
    "\n",
    "##################################### Base Chains ###########################################\n",
    "# 1. Input Translation Chain\n",
    "def translate_input(user_input):\n",
    "    \"\"\"Auto-detect and translate the user input to English.\"\"\"\n",
    "    try:\n",
    "        detected_lang = translator.detect_language(user_input).result\n",
    "        if detected_lang != \"English\":\n",
    "            user_input = translator.translate(user_input, destination_language=\"English\").result\n",
    "        return user_input, detected_lang\n",
    "    except Exception as e:\n",
    "        #st.error(f\"Error in language detection or translation: {e}\")\n",
    "        return user_input, \"English\"  # Default to English if detection fails\n",
    "\n",
    "# 2. Output Translation Chain\n",
    "def translate_output(response, target_lang):\n",
    "    \"\"\"Translate response back to the user's language.\"\"\"\n",
    "    try:\n",
    "        if target_lang != \"English\":\n",
    "            response = translator.translate(response, destination_language=target_lang).result\n",
    "        return response\n",
    "    except Exception as e:\n",
    "        #st.error(f\"Error in translating response: {e}\")\n",
    "        return response  # Return the original response if translation fails\n",
    "\n",
    "# 3. Fallback Error Handling Chain\n",
    "fallback_chain = (\n",
    "    ChatPromptTemplate.from_template(\"\"\"\n",
    "You are a fallback assistant. If the system cannot handle the query, respond politely and suggest contacting support.\n",
    "Input Query: \"{query}\"\n",
    "\"\"\")\n",
    "    | llama\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "##################################### Advanced Chains ###########################################\n",
    "# 4. Customization Chain\n",
    "custom_chain = (\n",
    "    ChatPromptTemplate.from_template(\"\"\"\n",
    "You are assisting a small business that specializes in {business_type}. Tailor your response to reflect the company's services and brand tone.\n",
    "Give answer in long form.\n",
    "The user query is: \"{query}\".\n",
    "\"\"\")\n",
    "    | llama\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "# 8. Contextual Query Chain\n",
    "context_chain = (\n",
    "    ChatPromptTemplate.from_template(\"\"\"\n",
    "You are a follow-up assistant. Based on the previous interaction: \"{previous_interaction}\", suggest a related query or provide further assistance.\n",
    "\"\"\")\n",
    "    | llama\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "# Create form to collect both inputs\n",
    "with st.form(\"user_query_form\"):\n",
    "    business_type = st.text_input(\"Business Type (e.g., Restaurant, Salon, etc.):\")\n",
    "    user_input = st.text_input(\"Ask your question here:\")\n",
    "\n",
    "    # Submit button for the form\n",
    "    submit_button = st.form_submit_button(label=\"Submit\")\n",
    "\n",
    "if submit_button:\n",
    "    if business_type and user_input:\n",
    "        # Translate input to English\n",
    "        translated_input, user_lang = translate_input(user_input)\n",
    "\n",
    "        # Generate response using the custom chain\n",
    "        response = custom_chain.invoke({\"business_type\": business_type, \"query\": translated_input})\n",
    "        \n",
    "        # Translate output back to user language\n",
    "        if response:\n",
    "            translated_response = translate_output(response, user_lang)\n",
    "            st.write(\"Response:\", translated_response)\n",
    "\n",
    "        # Contextual Suggestions\n",
    "        if st.checkbox(\"Need more help? Get suggestions.\"):\n",
    "            contextual_response = context_chain.invoke({\"previous_interaction\": translated_input})\n",
    "            st.write(\"Suggestions:\", contextual_response)\n",
    "    else:\n",
    "        st.warning(\"Please provide both Business Type and your Question.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Booking page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Requirements\n",
    "from langchain_groq import ChatGroq\n",
    "import streamlit as st\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from googletrans import Translator  # Multilingual support\n",
    "\n",
    "\n",
    "#LLM Model\n",
    "llama = ChatGroq(\n",
    "    model=\"LLaMA3-70B-8192\",\n",
    "    groq_api_key='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',\n",
    "    temperature=0.0\n",
    ")\n",
    "\n",
    "translator = Translator()  # Translator for multilingual support\n",
    "\n",
    "##################################### Base Chains ###########################################\n",
    "# 1. Input Translation Chain\n",
    "def translate_input(user_input):\n",
    "    \"\"\"Auto-detect and translate the user input to English.\"\"\"\n",
    "    try:\n",
    "        detected_lang = translator.detect_language(user_input).result\n",
    "        if detected_lang != \"English\":\n",
    "            user_input = translator.translate(user_input, destination_language=\"English\").result\n",
    "        return user_input, detected_lang\n",
    "    except Exception as e:\n",
    "        #st.error(f\"Error in language detection or translation: {e}\")\n",
    "        return user_input, \"English\"  # Default to English if detection fails\n",
    "\n",
    "# 2. Output Translation Chain\n",
    "def translate_output(response, target_lang):\n",
    "    \"\"\"Translate response back to the user's language.\"\"\"\n",
    "    try:\n",
    "        if target_lang != \"English\":\n",
    "            response = translator.translate(response, destination_language=target_lang).result\n",
    "        return response\n",
    "    except Exception as e:\n",
    "        #st.error(f\"Error in translating response: {e}\")\n",
    "        return response  # Return the original response if translation fails\n",
    "\n",
    "# 3. Fallback Error Handling Chain\n",
    "fallback_chain = (\n",
    "    ChatPromptTemplate.from_template(\"\"\"\n",
    "You are a fallback assistant. If the system cannot handle the query, respond politely and suggest contacting support.\n",
    "Input Query: \"{query}\"\n",
    "\"\"\")\n",
    "    | llama\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "##################################### Advanced Chains ###########################################\n",
    "# 5. Booking Management Chain\n",
    "booking_chain = (\n",
    "    ChatPromptTemplate.from_template(\"\"\"\n",
    "You are a virtual assistant that manages bookings for a business. The user wants to {action} for a service: \"{service}\" on the following date and time {date}{time}. \n",
    "If they provide a time or date, confirm the booking; if not, ask for more details.\n",
    "\"\"\")\n",
    "    | llama\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "# 8. Contextual Query Chain\n",
    "context_chain = (\n",
    "    ChatPromptTemplate.from_template(\"\"\"\n",
    "You are a follow-up assistant. Based on the previous interaction: \"{previous_interaction}\", suggest a related query or provide further assistance.\n",
    "\"\"\")\n",
    "    | llama\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "service = st.text_input(\"Service Type (e.g., Haircut, Meeting, etc.):\")\n",
    "\n",
    "action = st.text_input(\"Action (e.g., Book, Cancel, Reschedule):\")\n",
    "\n",
    "date = st.date_input(\"When to perfom action?\", value=None)\n",
    "\n",
    "time = st.time_input(\"Set an alarm for\", value=None)\n",
    "\n",
    "\n",
    "if service:\n",
    "    # Base Chain: Translate input to English\n",
    "    translated_input, user_lang = translate_input(service)\n",
    "    if service and action:\n",
    "        response = booking_chain.invoke({\"action\": action, \"service\": service, \"date\": date, \"time\": time})\n",
    "    else:\n",
    "        response = fallback_chain.invoke({\"query\": \"Missing service or action details.\"})\n",
    "\n",
    "\n",
    "    # Base Chain: Translate output back to user language\n",
    "    if response:\n",
    "        translated_response = translate_output(response, user_lang)\n",
    "        st.write(\"Response:\", translated_response)\n",
    "\n",
    "    # Contextual Suggestions\n",
    "    if st.checkbox(\"Need more help? Get suggestions.\"):\n",
    "        contextual_response = context_chain.invoke({\"previous_interaction\": translated_input})\n",
    "        st.write(\"Suggestions:\", contextual_response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chat Bot page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Requirements\n",
    "from langchain_groq import ChatGroq\n",
    "import streamlit as st\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from googletrans import Translator  # Multilingual support\n",
    "from langchain_core.messages import SystemMessage\n",
    "from langchain_core.prompts import (\n",
    "    ChatPromptTemplate,\n",
    "    HumanMessagePromptTemplate,\n",
    "    MessagesPlaceholder,\n",
    ")\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain.chains import LLMChain\n",
    "\n",
    "#LLM Model\n",
    "llama = ChatGroq(\n",
    "    model=\"LLaMA3-70B-8192\",\n",
    "    groq_api_key='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',\n",
    "    temperature=0.0\n",
    ")\n",
    "\n",
    "translator = Translator()  # Translator for multilingual support\n",
    "##################################### Base Chains ###########################################\n",
    "\n",
    "Chat_chain = (\n",
    "    \n",
    "    ChatPromptTemplate.from_template(\"\"\"\n",
    "You are an ai chatbot fine tuned for buisness and sales.\n",
    "You are made for assistance for Small buisnesses to grow them. The customer will chat {userinput} with you and you will service them.\n",
    "Here is the following services you will provide:\n",
    "                                     resolve the customer queries; \n",
    "                                     provide product information; \n",
    "                                     book, cancel, or re-schedule any product or service; \n",
    "                                     provide customized solutions for queries; \n",
    "                                     Help customer to choose the best product or service according to their needs or requirements.\n",
    "\"\"\")\n",
    "    | llama\n",
    "    | StrOutputParser()  \n",
    ")\n",
    "\n",
    "\n",
    "# 1. Input Translation Chain\n",
    "def translate_input(userinput):\n",
    "    \"\"\"Auto-detect and translate the user input to English.\"\"\"\n",
    "    try:\n",
    "        detected_lang = translator.detect_language(userinput).result\n",
    "        if detected_lang != \"English\":\n",
    "            userinput = translator.translate(userinput, destination_language=\"English\").result\n",
    "        return userinput, detected_lang\n",
    "    except Exception as e:\n",
    "        #st.error(f\"Error in language detection or translation: {e}\")\n",
    "        return userinput, \"English\"  # Default to English if detection fails\n",
    "\n",
    "# 2. Output Translation Chain\n",
    "def translate_output(response, target_lang):\n",
    "    \"\"\"Translate response back to the user's language.\"\"\"\n",
    "    try:\n",
    "        if target_lang != \"English\":\n",
    "            response = translator.translate(response, destination_language=target_lang).result\n",
    "        return response\n",
    "    except Exception as e:\n",
    "        #st.error(f\"Error in translating response: {e}\")\n",
    "        return response  # Return the original response if translation fails\n",
    "\n",
    "\n",
    "if \"messages\" not in st.session_state:\n",
    "    st.session_state.messages = []\n",
    "\n",
    "# getting User input\n",
    "userinput = st.chat_input(\"How can I help you?\")\n",
    "with st.chat_message(\"user\"):\n",
    "        st.write(userinput)\n",
    "\n",
    "\n",
    "if userinput:\n",
    "    message = st.chat_message(\"assistant\")\n",
    "    #message.write(cbt_chain.invoke(user_input))\n",
    "    # Base Chain: Translate input to English\n",
    "    translated_input, user_lang = translate_input(userinput)\n",
    "    st.session_state.messages.append({\"role\": \"user\", \"content\": userinput})\n",
    "    response = Chat_chain.invoke(userinput)\n",
    "    # Base Chain: Translate output back to user language\n",
    "    if response:\n",
    "        translated_response = translate_output(response, user_lang)\n",
    "        st.write(\"Response:\", translated_response)     \n",
    "    st.session_state.messages.append({\"role\": \"assistant\", \"content\": response})\n",
    "    \n",
    "    \n",
    "    \n",
    "# Display chat history\n",
    "for message in st.session_state.messages:\n",
    "    if message[\"role\"] == \"user\":\n",
    "        st.write(f\"You: {message['content']}\")\n",
    "    else:\n",
    "        st.write(f\"Bot: {message['content']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import streamlit as st\n",
    "\n",
    "# Title\n",
    "st.title(\"AI Customer Support Assistant\")\n",
    "\n",
    "pages = {\n",
    "    \"Home\": [\n",
    "        st.Page(\"Home_sb.py\", title=\"Welcome!\"),\n",
    "    ],\n",
    "    \"General Query\": [\n",
    "        st.Page(\"Query.py\", title=\"Query\"),\n",
    "    ],\n",
    "    \"Booking Management\": [\n",
    "        st.Page(\"Booking.py\", title=\"Booking.\"),\n",
    "    ],\n",
    "    \"Product Information\": [\n",
    "        st.Page(\"Product_info.py\", title=\"Product Information\"),\n",
    "    ],\n",
    "    \"Customized Responses\": [\n",
    "        st.Page(\"Customization.py\", title=\"Customized Responses\"),\n",
    "    ],\n",
    "    \"Chat Bot\": [\n",
    "        st.Page(\"Chatbot.py\", title=\"Chat Bot\"),\n",
    "    ],\n",
    "    \"Financial Advisor\": [\n",
    "        st.Page(\"Financial.py\", title=\"Financial Advisor\"),\n",
    "    ]\n",
    "}\n",
    "\n",
    "# Navigation page execution\n",
    "pg = st.navigation(pages)\n",
    "pg.run()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
